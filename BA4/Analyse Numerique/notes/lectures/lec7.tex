\documentclass[../main.tex]{subfiles}
\begin{document}
\lecture{7}{Fri 08 Apr}{Resolution de systemes lineaires}
\section{Resolution de systemes lineaires}
On cherche a resoudre $Ax= b, A \in \mathbb{R}^{n\times n}$ inversible, $ b \in \mathbb{R}^n$.\\
Pour $n$ grand, la regle de Cramer donne des erreurs d'arrondi enorme.\\
On souhaite donc utiliser  la regle de Gauss.\\
On cherche a ecrire $A = LU$ , $L$ triangulaire inferieure et $U$ triangulaire superieure.\\
Si on obtient cette decomposition, on a
\[ 
Ax = b \implies LUx = b \implies 
\begin{cases}
Ly = b\\
Ux= y
\end{cases}
\]
Ainsi, $Ax= b$ devient la resolution de deux systemes triangulaires.\\
Combien d'operations faut-il pour calculer $y = L^{-1}B$?\\
Par elimination directe, il faut $ O( n^{2}) $ operations.\\
Ainsi, une fois que la decomposition $A= LU$ a ete faite, on peut toujours resoudre le systeme.\\
On se demande donc combien d'operations il faut pour calculer $L$ et $U$?\\
Cette decomposition n'est pas toujours possible, cependant, si $A$ est inversible $\exists P$ un pivoting tel que $PA$ admet une decomposition $LU$.\\
Une matrice pivoting est de la forme $ \left( e_{\sigma ( 1)} \ldots e_{ \sigma( n) }  \right) $.\\
Ainsi $ PAx = Pb$ peut se resoudre par elimination de Gauss.\\
L'elimination de Gauss est un algorithme en $ O( n^{3}) $ ( donc tres couteux ).\\
Donc on va essayer de trouver un algorithme plus efficace.\\
Il y a quelques autres problemes lies a $ LU$ tel que la stabilite.
\begin{defn}[matrice creuse]
	$A$ est creuse si $ \# nz ( A) = O( n) $ ou $ \# nz$ est le nombre de valeurs non nulles.
\end{defn}
Si $A$ est creuse, sa decomposition $LU$  n'est pas creuse, donc cette methode n'est pas viable en general.
\subsection{Quelques rappels sur les matrices}
On definit
\[ 
\N { A} _p = \max_{x}  \frac{ \N { Ax} }{\N { x} }
\]
\[ 
\N { x} _p = ( \sum_i |x_i| ^{p}) ^{\frac{1}{p}}
\]
et 
\[ 
\rho( A) = \max_i |\lambda_i|
\]
\begin{propo}
$\forall p$, on a 
\[ 
\N { A} _p \geq \rho( A) 
\]
et 
\[ 
\N { A}_2 = \rho( A) 
\]
\end{propo}
\begin{defn}
	Le conditionnement de $A$ est defini par
	\[ 
	K_p( A) = \N { A} _p \N { A^{-1}}_p
	\]
	si $A$ n'est pas inversible, le conditionnement de $A$ est $+ \infty $.\\
	On definit de plus
	\[ 
	K_2 ( A) = K( A) = \rho( A) \rho( A^{-1}) 
	\]
	
	
\end{defn}
\subsection{Methodes iteratives pour la resolution de systemes lineaires}
On se contente de calculer une suite $x^{k}$ une suite telle que $ \lim_{k \to  + \infty} x^{k} = x_*$ la solution.\\
On definit $ A= P - ( P-A) $ avec $ P$ une matrice a definir, alors
\[ 
Px_* - ( P-A) x_* = b
\]
Alors
\[ 
Px^{k+1}- ( P-A) x^{k}= b\implies P x^{k+1}= ( P-A) x^{k} + b
\]
Qui est un systeme verifie pour $x_*$.\\
On pose $r^{k}= b- Ax^{k}$ et on a donc
\[ 
\begin{cases}
P x^{k+1}= P x^{k} + r^{k}\\
x^{0}= x_0 \text{  a choisir } 
\end{cases}
\]
Pour calculer $x^{k+1}$, on doit pouvoir inverser $ P$ et donc $P$ doit etre simple a inverser.\\
La convergence $x^{k}\to x_*$ depend donc du choix de $P$.\\
Ecrivons $ A= A_D + A_L + A_U$.\\
On peut alors choisir $P = A_D + A_L$ ou  $ P= A_D$, dans les deux cas $ P$ est simple a inverser.
\subsection*{Methode de Richarson statique}
 La methode statique s'ecrit $ P x^{k+1}= P x^{k}+ \alpha r^{k}$ pour $\alpha $ une constante et la methode dynamique $ Px^{k+1}= Px^{k}+ \alpha_k r^{k}$ ou les $\alpha_k$ sont a choisir.\\







\end{document}	
