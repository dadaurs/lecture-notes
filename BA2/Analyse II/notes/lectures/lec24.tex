\documentclass[../main.tex]{subfiles}
\begin{document}
\lecture{24}{Wed 26 May}{equations lineaires du premier ordre}
\subsection{Equations lineaires du premier ordre ( scalaire) }
On considere a nouveau des equations differentielles de la forme
\[ 
	\begin{cases}
	u'( t) = f( t,u( t) ) , \quad t \in I \\
	u( t_0) = u_0, t_0 \in \ded I
	\end{cases}
\]
La solution sera de la forme
\[ 
u': J \subset I \to \mathbb{R}
\]
On dit que l'equation est lineaire si $f: I \times  \mathbb{R} \to \mathbb{R}$ est continue et de la forme
\[ 
	f( t,u) = g( t) - p( t) u
\]
avec $g,p \in C^{0}( I) $.\\
$f$ est donc une fonction affine par rapport a la deuxieme variable.\\
On dit egalement que l'equation differentielle est homogene si $g( t) =0$ ( sans second membre ).\\
On peut donc reecrire une edo lineaire du premier ordre
\[ 
\begin{cases}
	u'( t) + p( t) u( t) = g( t) \\
	u( t_0) = u_0
\end{cases}
\]
Soit $P: I \to \mathbb{R}$ une primitve de $p$ .
\[ 
	P( t) = \int_{  }^{ t }p( s) ds
\]
Notons que
\[ 
	\frac{d}{dt}\left( e^{P( t) } u( t) \right) = e^{P( t) } p( t) u( t) + e^{P( t)} u'( t) 
\]
Donc on remarque que $u$ est solution de l'equationn si et seulement si
\[ 
	\frac{d}{dt}\left( e^{P( t) } u( t)  \right) = e^{P( t) } g( t) .
\]
Donc, on a 
\[ 
	e^{P( t) } u( t) - e^{P( t_0) } u( t_0) = \int_{ t_0 }^{ t } e^{P( s) } g( s) ds
\]
Qui est l'unique solution globale de l'equation differentielle.\\
Si on prend en particulier $P( t) = \int_{ t_0 }^{ t }p( s) ds$ , on trouve
\[ 
	u( t) = e^{-P( t) } u_0 + \int_{ t_0 }^{ t } e^{- ( P( t) - P( s) ) ) } g( s) ds
\]
\subsection{Deuxieme procede pour trouver la solution}
\underline{Idee}: etudier separement le probleme homogene et le probleme non-homogene.\\
Le probleme est donne par
\[ 
	u'( t) = - p( t) u( t) , \quad t \in I
\]
L'integrale generale du probleme homogene est donne par
\[ 
	u( t) = Ce^{-P( t) } , \quad C \in \mathbb{R}
\]
en effet
\begin{align*}
	\frac{d}{dt}\left( e^{P( t) } u( t) \right) &= e^{P( t) } \left( p( t) u( t) + u'( t) \right) \\
	e^{P( t) } u( t) = C\\
	u( t) = C e^{- P( t) } 
\end{align*}
Le probleme non homogene 
\[ 
	u'( t) = - p( t) u( t) + g( t) , t \in I
\]
Soit $w( t) $ une solution de cette equation, alors
\[ 
	z( t) = w( t) + C e^{- P( t) } 
\]
est l'integrale generale de l'equation differentielle.\\
On verifie facilement que $z( t) $ satisfait
\[ 
	z'( t) = - p( t) z( t) + g( t) .
\]
Pour montrer que l'ensemble des solutions $z( t) = w( t) + C e^{- P( t) } $ est l'integrale generale, on suppose par l'absurde qu'il existe une autre solution $v( t) $ qui ne peut pas s'ecrire sous la forme `` $w( t) + C e^{- P( t) } $ ''.\\
Mais alors $n( t) = v( t) - w( t) $ ,
\begin{align*}
	n'( t) &= v'( t) - w'( t) \\
	       &= - p( t) v( t) + g( t)  + p( t) w( t)  - g( t) \\
	       &= - p( t)  ( v( t) - w( t) ) = - p( t) n( t) 
\end{align*}
Mais donc, $n( t) = C e^{- P( t) } \Rightarrow v( t) = w( t) + C e^{- P( t) } .$ 
\begin{rmq}
Une fois qu'on a l'integrale generale, pour resoudre le probleme de Cauchy, il suffit de trouver la bonne valeur de la constante.
\end{rmq}
\begin{exemple}
\[ 
\begin{cases}
	u'( t) = u( t) + 1\\
	u( 0) = 1
\end{cases}
\]
Alors, $p( t) = -1, g( t) =1$ 
\[ 
	P( t) = \int_{ t_0 }^{ t }p( s) ds = \int_{ t_0 =0}^{ t } -1 ds =  -t
\]
Donc, 
\begin{align*}
u( t) = e^{-P( t) } u_0 + \int_{ 0t }^{ t } e^{- ( P( t) - P( s) ) } g( s) ds\\
&= e^{t } u_0 - \int_{ 0 }^{ t } e^{t-s} ds = \ldots
\end{align*}
\end{exemple}
\subsection{EDO lineaire a coefficients constant}
Si $p( t) = \alpha, \forall t \in I, \alpha \in \mathbb{R}$ , alors
\[ 
	\begin{cases}
	u'( t) + \alpha u( t) = g( t) \\
	u( t_0) = u_0
	\end{cases}
\]
Alors l'integrale generale de l'equation homogene est $C e^{- \alpha t} $.\\
Si $g( t) $ est un polynome $g( t) = \sum_{}^{ } \gamma_j t^{j}$ .\\
On peut construire une solution particuliere sous la meme forme
\[ 
	w( t) = \sum_{j}^{ } \beta_j t^{j}
\]
En effet
\begin{align*}
	w'( t) &= \sum_{j=1}^{ n} j \beta_j t^{j-1} = \sum_{j=0}^{ n-1} ( j+1)  \beta_{j+1} t^{j}\\
	       &= \alpha w( t)  + g( t) \\
	       &= \alpha \sum_{j=0}^{ n} \beta_j t^{j} + \sum_{j=0}^{ n}\gamma_j t^{j}= \sum_{j=0}^{ n} ( \alpha \beta_j + \gamma_j ) t^{j}
\end{align*}
Donc
\[ 
	( j+1)  \beta_{j+1}  = \alpha \beta_j + \gamma_j, \quad j = 0 , \ldots, n-1
\]
et $ \beta_n = - \frac{\gamma_n }{\alpha}$ .\\
Si $g( t) $ est exponentiel,
\[ 
	- g( t) = e^{\delta t} 
\]
\begin{itemize}
	\item Si $\delta \neq - \alpha$, on cherche $w( t) = \beta e^{\delta t} $ 
		\[ 
			w'( t) = \beta \delta e^{\delta t} = \alpha w( t)  + g( t) =(  \alpha \beta + \gamma ) e^{\delta t} 
		\]
		Et donc on trouve
		\[ 
		\beta = \frac{\gamma }{\delta + \alpha}
		\]

	\item Si $\delta = -\alpha$, il faut chercher une solution particuliere de la forme 
		\[ 
			w( t) = \beta t e^{- \alpha t} 
		\]
		
		
\end{itemize}
Plus generalement, si 
\[ 
	g( t) = \left( \sum_{j=0}^{ n}\gamma_j t^{j} \right) e^{\delta t} 
\]
Alors on cherche $w( t) = \left( \sum_{j=0}^{ n}\beta_j t^{j}\right) e^{\delta t} $ si $ \delta \neq - \alpha$ et
$w( t) = t\left( \sum_{j=0}^{ n}\beta_j t^{j}\right) e^{\delta t} $  si $\delta = - \alpha$ .\\
Si $g( t) $ est une fonction trigonometrique
\[ 
	g( t) = \gamma_1 \sin ( \omega t) + \gamma 2 \cos ( \omega t) 
\]
on cherche
\[ 
	w( t) = \beta_1 \sin ( \omega t) + \beta_2 \cos ( \omega t) 
\]
Alors
\begin{align*}
	w'( t)  &= \beta_1 \omega \cos ( \omega t) - \beta_2 \omega \sin ( \omega t) \\
		&= - \alpha w( t)  + g( t) 
\end{align*}
Et on peut donc faire coincider les coefficients.\\
Plus generalement, si $g( t) = \left( \sum_{j=0}^{ n}\gamma_j t^{j} \right) e^{\epsilon t} \sin ( \omega t) + \left( \sum_{j=0}^{ n}\tilde \gamma_j t^{j}\right) e^{\delta t} \cos ( \omega t) $ , on cherche
\[ 
	w( t) = \left( \sum_{j=0}^{ n} \beta_j t^{j} e^{\delta t} \sin ( \omega t )  \right) + \left( \sum_{j=0}^{ n} \beta_j t^{j} e^{\delta t} \cos ( \omega t )  \right)
\]
\subsection{Existence et unicite des solutions}
On considere une equation vectorielle .\\
Soit $I \subset  \mathbb{R}$ un intervalle ouvert, $E \subset  \mathbb{R}^n$ ouvert, $f : I \times E \to \mathbb{R}^n$ continue.\\
On cherche $\vec{u}: J \subset I \to \mathbb{R}^n$ tel que 
\[ 
	\begin{cases}
	\vec{u}'( t) = f( t,\vec{u}( t) ) , \forall t \in J\\
	\vec{u}( t_0) = \vec{u_0}
	\end{cases}
\]
\begin{thm}[Theoreme de Cauchy-Peano]
	Sous les hypotheses ci-dessus, pour tout $( t_0, \vec{u_0}) \in I \times E$. Le probleme de Cauchy admet au moins une solution locale $( J, \vec{u}) $ avec $J \subset I, t_0 \in \ded J$.
\end{thm}
\begin{defn}
	On dit qu'une fonction $\vec{f}: I \times E \to \mathbb{R}^n$ continue est localement lipschitz par rapport au deuxieme argument si pour tout $ ( t_0, u_0) \in I \times E$ , il existe $a,b >0$ avec $ [ t_0-a, t_0+a] \times \overline{B}( \vec{u_0}, b) \subset I \times E$ et une constante $L>0:$ 
	\[ 
		\forall t \in [ t_0-a, t_0+a] , \forall \vec{u},\vec{v} \in \overline{B}( u_0,b) 
	\]
	on a 
	\[ 
		\N {  \vec{f}( t,u) - \vec{f}( t,v)  } \leq L \N { \vec{u} - \vec{v}} 	
	\]

	
\end{defn}
\begin{thm}[de Cauchy-Lipschitz]
	Sous les memes hypotheses, si $\vec{f}$ est localement lipschitzienne par rapport au deuxieme argument, alors on a que $\forall ( t_0, \vec{u_0}) \in I \times E$ , il existe une unique solution locale $ ( J, \vec{u}) $ , avec $J \subset I$ , contenant $t_0$ .\\
	( solution locale unique signifie que tout autre solution locale $( K, w) $ avec $K \subset I$ , contenant $t_0$ , on a $ w( t) = u( t) ,\forall t \in K \cap J $   )
\end{thm}











\end{document}	
